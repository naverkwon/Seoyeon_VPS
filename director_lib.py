# director_lib.py
# Core logic, API calls, and file operations for VPS Director

import json
import requests
import websocket
import uuid
import urllib.request
import urllib.parse
import random
import time
from PIL import Image
import io
import os
from datetime import datetime
import subprocess
import google.generativeai as genai
import replicate
from dotenv import load_dotenv

# Load Env
load_dotenv()

# ==========================================
# Configuration
# ==========================================
COMFY_SERVER = "127.0.0.1:8188"
WORKFLOW_FILE = "Seoyeon_Flux_v1.json"
CLIENT_ID = str(uuid.uuid4())

# Replicate with LoRA
REPLICATE_MODEL = "lucataco/flux-dev-lora:091495765fa5ef2725a175a57b276ec30dc9d39c22d30410f2ede68a3eab66b3"
FLUX_LORA_URL = "https://huggingface.co/marine302/Seoyeon_flux/resolve/main/bdce2f3df07d7d36a56036ffd69d46ca.safetensors"

CHARACTER_TRIGGER = "seoyoon, beautiful korean woman, (k-pop idol:1.1)"

GEMINI_API_KEY = os.getenv("GEMINI_API_KEYS", "").split(',')[0] or os.getenv("GEMINI_API_KEY")
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# Negative Prompt (Fixed)
NEGATIVE_PROMPT = "nsfw, nude, naked, nipple, lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, artist name, (worst quality, low quality:1.4), (bad anatomy:1.4), (inaccurate limb:1.2), bad composition, inaccurate eyes, extra digit, fewer digits, (extra arms:1.2)"

# ==========================================
# Functions
# ==========================================

def save_image_to_disk(image, prompt):
    save_dir = os.path.join(os.getcwd(), "generated_images")
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
    filename = f"{int(time.time())}_{uuid.uuid4().hex[:6]}.png"
    filepath = os.path.join(save_dir, filename)
    image.save(filepath)
    return filepath

def generate_caption(prompt):
    if not GEMINI_API_KEY: return "Generated by VPS Director"
    try:
        model = genai.GenerativeModel('gemini-flash-latest')
        p = f"Write a short, engaging Instagram caption (in Korean) for a photo satisfying this prompt: '{prompt}'. Add hashtags. Tone: K-pop Idol Seoyeon."
        return model.generate_content(p).text.strip()
    except:
        return "✨ 서연이의 일상 #Seoyeon #Daily"

def translate_to_eng(text):
    if not text or text == "(직접 입력)": return ""
    if not GEMINI_API_KEY: return text
    if all(ord(c) < 128 for c in text.replace(" ", "")): return text
    try:
        model = genai.GenerativeModel('gemini-flash-latest')
        prompt = f"Translate to specific English prompt tag: {text}"
        return model.generate_content(prompt).text.strip()
    except:
        return text

def generate_ai_action():
    if not GEMINI_API_KEY: return "Error: No API Key"
    model = genai.GenerativeModel('gemini-flash-latest')
    scenarios = [
        "drinking iced americano at a trendy cafe", "reading a book in a library", 
        "fixing hair while looking at a mirror", "walking down a busy street at night",
        "stretching at the gym", "eating a strawberry cake happily"
    ]
    prompt = f"Suggest ONE creative, vivid photo action scenario for a K-pop idol photoshoot. Short phrase in Korean. Example: {random.choice(scenarios)}"
    try: return model.generate_content(prompt).text.strip()
    except: return "벤치에 앉아 쉬는 중"

def generate_random_theme():
    """Pick a random theme from the predefined list in director_data."""
    # Lazy import to avoid circular dependency
    import director_data as dd
    return random.choice(dd.STORY_THEMES)

def generate_storyboard(theme, platform, count=6):
    if not GEMINI_API_KEY: return []
    model = genai.GenerativeModel('gemini-flash-latest')
    prompt = f"""
    Act as a professional K-pop visual director.
    Plan a {count}-shot storyboard for Seoyeon's {platform} feed.
    Theme: {theme}
    Output structured JSON ONLY with keys: title, shot_type (Close-up, Upper Body, Cowboy Shot, Full Body), visual_prompt.
    """
    try:
        txt = model.generate_content(prompt).text.strip()
        if "```json" in txt: txt = txt.split("```json")[1].split("```")[0]
        elif "```" in txt: txt = txt.split("```")[1].split("```")[0]
        return json.loads(txt)
    except Exception as e:
        print(f"Error: {e}")
        return []

def save_metadata(filename, prompt, seed, caption):
    metadata_file = os.path.join(os.getcwd(), "gallery_metadata.json")
    data = {}
    
    if os.path.exists(metadata_file):
        try:
            with open(metadata_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except:
            pass
            
    # Extract tags (simple heuristic)
    tags = ""
    if "#" in caption:
        tags = "#" + caption.split("#", 1)[1]
        
    data[os.path.basename(filename)] = {
        "prompt": prompt,
        "seed": seed,
        "caption": caption,
        "tags": tags,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    
    with open(metadata_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def check_server():
    try:
        requests.get(f"http://{COMFY_SERVER}/system_stats", timeout=1)
        return True
    except:
        return False

def queue_prompt(workflow):
    p = {"prompt": workflow, "client_id": CLIENT_ID}
    req = urllib.request.Request(f"http://{COMFY_SERVER}/prompt", data=json.dumps(p).encode('utf-8'))
    return json.loads(urllib.request.urlopen(req).read())

def get_history(prompt_id):
    with urllib.request.urlopen(f"http://{COMFY_SERVER}/history/{prompt_id}") as response:
        return json.loads(response.read())

def get_image_data(filename, subfolder, folder_type):
    qs = urllib.parse.urlencode({"filename": filename, "subfolder": subfolder, "type": folder_type})
    with urllib.request.urlopen(f"http://{COMFY_SERVER}/view?{qs}") as response:
        return response.read()

def open_folder(path):
    if os.path.exists(path): subprocess.run(["open", path])

def generate_image(engine, prompt, seed):
    """
    Unified function to generate images via Local ComfyUI or Cloud Replicate.
    Returns: PIL.Image object.
    Raises: Exception with detailed message on failure.
    """
    if "ComfyUI" in engine or "Local" in engine:
        # === LOCAL (ComfyUI) ===
        try:
            with open(WORKFLOW_FILE, "r") as f: wf = json.load(f)
        except FileNotFoundError:
            raise Exception(f"Workflow file '{WORKFLOW_FILE}' not found.")
        
        # Update workflow nodes
        wf["6"]["inputs"]["text"] = prompt
        wf["3"]["inputs"]["seed"] = seed
        
        # Connect & Queue
        try:
            ws = websocket.WebSocket()
            ws.connect(f"ws://{COMFY_SERVER}/ws?clientId={CLIENT_ID}")
        except Exception:
            raise Exception(f"Could not connect to ComfyUI at {COMFY_SERVER}. Is it running?")

        pid = queue_prompt(wf)['prompt_id']
        
        # Wait for execution
        while True:
            out = ws.recv()
            if 'executing' in out and json.loads(out)['data']['node'] is None: break
        
        # Retrieve Output
        h = get_history(pid)
        if not h: raise Exception("No history returned from ComfyUI.")

        # Find output image (Node 9)
        outputs = h[pid]['outputs']
        if '9' not in outputs:
             # Try to find any images output
             for node_id, node_out in outputs.items():
                 if 'images' in node_out:
                     outputs = { '9': node_out } # Fake it
                     break
             else:
                 raise Exception("No image output found in ComfyUI result.")

        for o in outputs['9']['images']:
            raw = get_image_data(o['filename'], o['subfolder'], o['type'])
            return Image.open(io.BytesIO(raw))
            
    else:
        # === CLOUD (Replicate) ===
        if not os.environ.get("REPLICATE_API_TOKEN"):
             raise Exception("REPLICATE_API_TOKEN not found in environment variables.")

        # [SAFETY FILTER] Strip risky terms for Cloud to avoid ban/error
        # We keep the "Concept" but remove "Explicit Visuals"
        risky_terms = [
            "nipple", "nude", "naked", "uncensored", "nsfw", "areola",
            "pendulous breasts", "realistic slight sag", "large soft breasts", # From PROMPT_BODY
            "pubic hair", "cameltoe", "pussy", "vagina", "sex", "fuck"
        ]
        
        safe_prompt = prompt
        for term in risky_terms:
            safe_prompt = safe_prompt.replace(term, "")
            
        print(f"☁️ [Cloud Safety] Original: {len(prompt)} chars -> Safe: {len(safe_prompt)} chars")

        input_payload = {
            "prompt": safe_prompt, # Use Sanitized Prompt
            "hf_lora": FLUX_LORA_URL,
            "lora_scale": 0.95,
            "num_inference_steps": 30,
            "guidance_scale": 3.5,
            "width": 800,
            "height": 1200,
            "output_format": "jpg",
            "output_quality": 100,
            "seed": seed,
            "disable_safety_checker": True # Still disable checker to avoid false positives on "skin"
        }
        
        try:
            output = replicate.run(REPLICATE_MODEL, input=input_payload)
        except Exception as e:
            raise Exception(f"Replicate API Error: {str(e)}")

        url = output[0] if isinstance(output, list) else output
        if not url: raise Exception("Replicate returned no URL.")
        
        return Image.open(io.BytesIO(requests.get(url).content))
